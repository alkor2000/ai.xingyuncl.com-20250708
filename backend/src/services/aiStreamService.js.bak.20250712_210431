/**
 * 流式AI服务
 * 处理流式API调用和Server-Sent Events
 */

const axios = require('axios');
const AIModel = require('../models/AIModel');
const logger = require('../utils/logger');
const { ExternalServiceError } = require('../utils/errors');

class AIStreamService {
  /**
   * 发送流式消息到AI模型
   * @param {Object} res - Express响应对象，用于SSE
   * @param {string} modelName - 模型名称
   * @param {Array} messages - 消息数组
   * @param {Object} options - 配置选项
   * @returns {Promise} 流式处理Promise
   */
  static async sendStreamMessage(res, modelName, messages, options = {}) {
    try {
      logger.info('开始流式AI服务调用', { 
        model: modelName, 
        messageCount: messages.length,
        customTemperature: options.temperature 
      });

      // 获取AI模型配置
      const model = await AIModel.findByName(modelName);
      if (!model) {
        throw new Error(`AI模型 ${modelName} 未找到或未启用`);
      }

      // 检查模型是否支持流式输出
      if (!model.stream_enabled) {
        throw new Error(`AI模型 ${modelName} 不支持流式输出`);
      }

      // 设置SSE响应头
      res.setHeader('Content-Type', 'text/event-stream');
      res.setHeader('Cache-Control', 'no-cache');
      res.setHeader('Connection', 'keep-alive');
      res.setHeader('X-Accel-Buffering', 'no'); // 禁用Nginx缓冲

      // 发送初始连接成功事件
      res.write('event: connected\ndata: {"status": "connected"}\n\n');

      // 如果有初始化数据，发送初始化事件
      if (options.userMessage || options.creditsInfo) {
        const initData = {
          user_message: options.userMessage,
          ai_message_id: options.messageId,
          credits_info: options.creditsInfo
        };
        res.write(`event: init\ndata: ${JSON.stringify(initData)}\n\n`);
      }

      // 调用流式API
      return await AIStreamService.callStreamAPI(res, model, messages, options);
    } catch (error) {
      logger.error('流式AI服务调用失败:', error);
      
      // 发送错误事件
      res.write(`event: error\ndata: ${JSON.stringify({ error: error.message })}\n\n`);
      res.end();
      
      throw new ExternalServiceError(`流式AI服务调用失败: ${error.message}`, 'ai');
    }
  }

  /**
   * 调用模型流式API
   */
  static async callStreamAPI(res, model, messages, options = {}) {
    let fullContent = '';
    let tokenCount = 0;
    const startTime = Date.now();
    
    try {
      if (!model.api_key || !model.api_endpoint) {
        throw new Error(`模型 ${model.name} 的API密钥或端点未配置`);
      }

      // 合并配置
      const modelConfig = model.getDefaultConfig();
      const requestConfig = {
        ...modelConfig,
        ...options
      };

      // 使用会话级temperature
      const finalTemperature = options.temperature !== undefined ? 
        parseFloat(options.temperature) : 
        (requestConfig.temperature || 0.7);

      logger.info('调用流式AI模型API', { 
        model: model.name, 
        endpoint: model.api_endpoint,
        messageCount: messages.length,
        temperature: finalTemperature
      });

      // 构造请求数据
      const requestData = {
        model: model.name,
        messages: messages,
        temperature: finalTemperature,
        top_p: requestConfig.top_p || 1,
        presence_penalty: requestConfig.presence_penalty || 0,
        frequency_penalty: requestConfig.frequency_penalty || 0,
        stream: true // 开启流式模式
      };

      const endpoint = model.api_endpoint.endsWith('/chat/completions') ? 
        model.api_endpoint : 
        `${model.api_endpoint}/chat/completions`;

      // 发起流式请求
      const response = await axios({
        method: 'post',
        url: endpoint,
        data: requestData,
        headers: {
          'Authorization': `Bearer ${model.api_key}`,
          'Content-Type': 'application/json',
          'Accept': 'text/event-stream'
        },
        responseType: 'stream',
        timeout: 120000 // 2分钟超时
      });

      // 返回Promise以便等待流式完成
      return new Promise((resolve, reject) => {
        // 处理流式响应
        response.data.on('data', (chunk) => {
          try {
            const lines = chunk.toString().split('\n').filter(line => line.trim() !== '');
            
            for (const line of lines) {
              if (line.startsWith('data: ')) {
                const jsonStr = line.slice(6);
                
                // 检查是否是结束标记
                if (jsonStr === '[DONE]') {
                  // 发送完成事件
                  const completionData = {
                    content: fullContent,
                    tokens: tokenCount,
                    duration: Date.now() - startTime,
                    messageId: options.messageId,
                    conversationId: options.conversationId
                  };
                  
                  res.write(`event: done\ndata: ${JSON.stringify(completionData)}\n\n`);
                  res.end();
                  
                  // 调用完成回调
                  if (options.onComplete) {
                    options.onComplete(fullContent, tokenCount);
                  }
                  
                  resolve({
                    content: fullContent,
                    tokens: tokenCount
                  });
                  return;
                }
                
                try {
                  const data = JSON.parse(jsonStr);
                  const content = data.choices?.[0]?.delta?.content || '';
                  
                  if (content) {
                    fullContent += content;
                    tokenCount++;
                    
                    // 发送内容片段
                    res.write(`event: message\ndata: ${JSON.stringify({
                      content: content,
                      fullContent: fullContent
                    })}\n\n`);
                  }
                } catch (parseError) {
                  logger.warn('解析流式数据失败:', parseError.message);
                }
              }
            }
          } catch (error) {
            logger.error('处理流式数据失败:', error);
          }
        });

        response.data.on('error', (error) => {
          logger.error('流式响应错误:', error);
          res.write(`event: error\ndata: ${JSON.stringify({ error: error.message })}\n\n`);
          res.end();
          reject(error);
        });

        response.data.on('end', () => {
          // 确保连接已关闭
          if (!res.writableEnded) {
            const completionData = {
              content: fullContent,
              tokens: tokenCount,
              duration: Date.now() - startTime,
              messageId: options.messageId,
              conversationId: options.conversationId
            };
            
            res.write(`event: done\ndata: ${JSON.stringify(completionData)}\n\n`);
            res.end();
          }
          
          resolve({
            content: fullContent,
            tokens: tokenCount
          });
        });
      });

    } catch (error) {
      logger.error('流式模型API调用失败:', error);
      
      if (error.response) {
        logger.error('API错误响应:', error.response.data);
      }
      
      throw error;
    }
  }

  /**
   * 估算流式内容的Token数量
   */
  static estimateStreamTokens(content) {
    if (!content || typeof content !== 'string') {
      return 0;
    }
    
    const chineseChars = (content.match(/[\u4e00-\u9fa5]/g) || []).length;
    const otherChars = content.length - chineseChars;
    
    return Math.ceil(chineseChars * 0.67 + otherChars * 0.25);
  }
}

module.exports = AIStreamService;
