/**
 * 流式AI服务
 * 处理流式API调用和Server-Sent Events - 支持图片识别
 */

const axios = require('axios');
const AIModel = require('../models/AIModel');
const File = require('../models/File');
const logger = require('../utils/logger');
const { ExternalServiceError } = require('../utils/errors');

class AIStreamService {
  /**
   * 发送流式消息到AI模型
   * @param {Object} res - Express响应对象，用于SSE
   * @param {string} modelName - 模型名称
   * @param {Array} messages - 消息数组
   * @param {Object} options - 配置选项
   * @returns {Promise} 流式处理Promise
   */
  static async sendStreamMessage(res, modelName, messages, options = {}) {
    try {
      logger.info('开始流式AI服务调用', { 
        model: modelName, 
        messageCount: messages.length,
        customTemperature: options.temperature,
        hasImages: messages.some(m => m.image_url)
      });

      // 获取AI模型配置
      const model = await AIModel.findByName(modelName);
      if (!model) {
        throw new Error(`AI模型 ${modelName} 未找到或未启用`);
      }

      // 检查模型是否支持流式输出
      if (!model.stream_enabled) {
        throw new Error(`AI模型 ${modelName} 不支持流式输出`);
      }

      // 设置SSE响应头 - 关键配置
      res.writeHead(200, {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache, no-transform',
        'Connection': 'keep-alive',
        'X-Accel-Buffering': 'no', // 禁用Nginx缓冲
        'Access-Control-Allow-Origin': '*'
      });

      // 立即flush确保头部发送
      res.flushHeaders();

      // 发送初始连接成功事件
      res.write('event: connected\ndata: {"status": "connected"}\n\n');

      // 如果有初始化数据，发送初始化事件
      if (options.userMessage || options.creditsInfo) {
        const initData = {
          user_message: options.userMessage,
          ai_message_id: options.messageId,
          credits_info: options.creditsInfo
        };
        res.write(`event: init\ndata: ${JSON.stringify(initData)}\n\n`);
      }

      // 调用流式API
      return await AIStreamService.callStreamAPI(res, model, messages, options);
    } catch (error) {
      logger.error('流式AI服务调用失败:', error);
      
      // 发送错误事件
      if (!res.writableEnded) {
        res.write(`event: error\ndata: ${JSON.stringify({ error: error.message })}\n\n`);
        res.end();
      }
      
      throw new ExternalServiceError(`流式AI服务调用失败: ${error.message}`, 'ai');
    }
  }

  /**
   * 调用模型流式API
   */
  static async callStreamAPI(res, model, messages, options = {}) {
    let fullContent = '';
    let tokenCount = 0;
    const startTime = Date.now();
    let buffer = ''; // 用于处理不完整的数据块
    let messageCount = 0;
    
    try {
      if (!model.api_key || !model.api_endpoint) {
        throw new Error(`模型 ${model.name} 的API密钥或端点未配置`);
      }

      // 合并配置
      const modelConfig = model.getDefaultConfig();
      const requestConfig = {
        ...modelConfig,
        ...options
      };

      // 使用会话级temperature
      const finalTemperature = options.temperature !== undefined ? 
        parseFloat(options.temperature) : 
        (requestConfig.temperature || 0.7);

      logger.info('调用流式AI模型API', { 
        model: model.name, 
        endpoint: model.api_endpoint,
        messageCount: messages.length,
        temperature: finalTemperature,
        supportsImages: model.image_upload_enabled
      });

      // 处理包含图片的消息
      const processedMessages = messages.map(msg => {
        if (msg.image_url && model.image_upload_enabled) {
          // 根据不同的模型API格式处理图片
          if (model.provider === 'openai') {
            return {
              role: msg.role,
              content: [
                { type: 'text', text: msg.content },
                { type: 'image_url', image_url: { url: msg.image_url } }
              ]
            };
          } else if (model.provider === 'anthropic') {
            // Claude格式（如果需要）
            return {
              role: msg.role,
              content: msg.content,
              // Claude的图片处理方式可能不同
            };
          } else {
            // 其他模型保持原格式
            return {
              role: msg.role,
              content: msg.content
            };
          }
        }
        return msg;
      });

      // 构造请求数据
      const requestData = {
        model: model.name,
        messages: processedMessages,
        temperature: finalTemperature,
        top_p: requestConfig.top_p || 1,
        presence_penalty: requestConfig.presence_penalty || 0,
        frequency_penalty: requestConfig.frequency_penalty || 0,
        stream: true // 开启流式模式
      };

      const endpoint = model.api_endpoint.endsWith('/chat/completions') ? 
        model.api_endpoint : 
        `${model.api_endpoint}/chat/completions`;

      // 发起流式请求
      const response = await axios({
        method: 'post',
        url: endpoint,
        data: requestData,
        headers: {
          'Authorization': `Bearer ${model.api_key}`,
          'Content-Type': 'application/json',
          'Accept': 'text/event-stream'
        },
        responseType: 'stream',
        timeout: 180000 // 3分钟超时，图片处理可能需要更长时间
      });

      logger.info('流式响应开始接收');

      // 返回Promise以便等待流式完成
      return new Promise((resolve, reject) => {
        // 处理流式响应
        response.data.on('data', (chunk) => {
          try {
            // 将chunk转换为字符串并添加到buffer
            buffer += chunk.toString();
            
            // 按行分割，处理完整的行
            const lines = buffer.split('\n');
            
            // 保留最后一个可能不完整的行
            buffer = lines.pop() || '';
            
            for (const line of lines) {
              const trimmedLine = line.trim();
              if (!trimmedLine || trimmedLine === '') continue;
              
              // 处理SSE格式: data: {...}
              if (trimmedLine.startsWith('data: ')) {
                const jsonStr = trimmedLine.slice(6);
                
                // 检查是否是结束标记
                if (jsonStr === '[DONE]') {
                  logger.info('流式传输接收完成', {
                    totalMessages: messageCount,
                    contentLength: fullContent.length
                  });
                  
                  // 发送完成事件
                  const completionData = {
                    content: fullContent,
                    tokens: tokenCount,
                    duration: Date.now() - startTime,
                    messageId: options.messageId,
                    conversationId: options.conversationId
                  };
                  
                  res.write(`event: done\ndata: ${JSON.stringify(completionData)}\n\n`);
                  res.end();
                  
                  // 调用完成回调
                  if (options.onComplete) {
                    options.onComplete(fullContent, tokenCount);
                  }
                  
                  resolve({
                    content: fullContent,
                    tokens: tokenCount
                  });
                  return;
                }
                
                try {
                  const data = JSON.parse(jsonStr);
                  const deltaContent = data.choices?.[0]?.delta?.content;
                  
                  if (deltaContent && deltaContent !== '') {
                    messageCount++;
                    fullContent += deltaContent;
                    tokenCount += AIStreamService.estimateStreamTokens(deltaContent);
                    
                    // 发送内容片段 - 确保格式正确
                    const messageData = {
                      content: deltaContent,
                      fullContent: fullContent
                    };
                    
                    res.write(`event: message\ndata: ${JSON.stringify(messageData)}\n\n`);
                    
                    // 每10个片段记录一次日志
                    if (messageCount % 10 === 0) {
                      logger.debug('流式片段进度', {
                        messages: messageCount,
                        contentLength: fullContent.length
                      });
                    }
                  }
                } catch (parseError) {
                  logger.warn('解析流式数据失败:', {
                    error: parseError.message,
                    data: jsonStr.substring(0, 100)
                  });
                }
              }
            }
          } catch (error) {
            logger.error('处理流式数据块失败:', error);
          }
        });

        response.data.on('error', (error) => {
          logger.error('流式响应错误:', error);
          if (!res.writableEnded) {
            res.write(`event: error\ndata: ${JSON.stringify({ error: error.message })}\n\n`);
            res.end();
          }
          reject(error);
        });

        response.data.on('end', () => {
          logger.info('流式响应接收结束');
          
          // 如果还有未处理的buffer数据，尝试处理
          if (buffer.trim()) {
            logger.warn('存在未处理的流式数据:', buffer);
          }
          
          // 确保连接已关闭
          if (!res.writableEnded) {
            const completionData = {
              content: fullContent,
              tokens: tokenCount,
              duration: Date.now() - startTime,
              messageId: options.messageId,
              conversationId: options.conversationId
            };
            
            res.write(`event: done\ndata: ${JSON.stringify(completionData)}\n\n`);
            res.end();
          }
          
          resolve({
            content: fullContent,
            tokens: tokenCount
          });
        });

        // 处理超时
        const timeoutId = setTimeout(() => {
          logger.error('流式响应超时');
          if (!res.writableEnded) {
            res.write(`event: error\ndata: ${JSON.stringify({ error: 'Stream timeout' })}\n\n`);
            res.end();
          }
          reject(new Error('流式响应超时'));
        }, 180000);

        response.data.on('end', () => clearTimeout(timeoutId));
        response.data.on('error', () => clearTimeout(timeoutId));
      });

    } catch (error) {
      logger.error('流式模型API调用失败:', {
        error: error.message,
        response: error.response?.data
      });
      
      throw error;
    }
  }

  /**
   * 估算流式内容的Token数量
   */
  static estimateStreamTokens(content) {
    if (!content || typeof content !== 'string') {
      return 0;
    }
    
    const chineseChars = (content.match(/[\u4e00-\u9fa5]/g) || []).length;
    const otherChars = content.length - chineseChars;
    
    return Math.ceil(chineseChars * 0.67 + otherChars * 0.25);
  }
}

module.exports = AIStreamService;
